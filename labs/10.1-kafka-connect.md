<link rel='stylesheet' href='../assets/css/main.css'/>

[<< back to main index](../README.md)

# Lab 10.1: Kafka Connect

### Overview
Write data from a local file to a Kafka topic

### Depends On

### Run time
40 mins


## Step 1: Start Kafka and ZooKeeper


## Step 2: Creating a Topic to Write to

In this lab we create the my-connect-test topic. Make sure KAFKA_HOME is set.
````bash
$ export KAFKA_HOME=$HOME/kafka
$ $KAFKA_HOME/bin/kafka-topics.sh \
      --create \
      --bootstrap-server localhost:9092 \
      --replication-factor 1 \
      --partitions 1 \
      --topic my-connect-test
````
## Step 3: Creating a Source Config File

Since we are reading the contents of a local file and writing to Kafka, this file is considered our “source”. Therefore we will use the FileSource connector. We must create a configuration file to use with this connector. For this most part you can copy the example available in $KAFKA_HOME/config/connect-file-source.properties. Below is an example of our my-file-source.properties file

    #my-file-source.properties config file
    name=local-file-source
    connector.class=FileStreamSource
    tasks.max=1
    file=/tmp/my-test.txt
    topic=my-connect-test
    
This file indicates that we will use the FileStreamSource connector class, read data from the /tmp.my-test.txt file, and publish records to the my-connect-test Kafka topic. We are also only using 1 task to push this data to Kafka, since we are reading/publishing a single file.

## Step 4: Creating a Worker Config File

You can find a sample config file for standalone workers in $KAFKA_HOME/config/connect-standalone.properties. We will call our file my-standalone.properties.
    
    # my-standalone.properties worker config file
     
    #bootstrap kafka servers
    bootstrap.servers=localhost:9092
     
    # specify input data format
    key.converter=org.apache.kafka.connect.storage.StringConverter
    value.converter=org.apache.kafka.connect.storage.StringConverter
     
    # The internal converter used for offsets, most will always want to use the built-in default
    internal.key.converter=org.apache.kafka.connect.json.JsonConverter
    internal.value.converter=org.apache.kafka.connect.json.JsonConverter
    internal.key.converter.schemas.enable=false
    internal.value.converter.schemas.enable=false
     
    # local file storing offsets and config data
    offset.storage.file.filename=/tmp/connect.offsets
    
The main change in this example in comparison to the default is the key.converter and value.converter settings. Since our file contains simple text, we use the StringConverter types.

## Step 5: Create the input source file
Create a file /tmp/my-test.txt and add in several lines of text. Here is an example:

    this is line 1
    this is line 2
    this is line 3


## Step 6: Running Kafka Connect
````bash
$  $KAFKA_HOME/bin/connect-standalone.sh $KAFKA_HOME/config/my-standalone.properties $KAFKA_HOME/config/my-file-source.properties
````

Our input file /tmp/my-test.txt will be read in a single process to the Kafka my-connect-test topic. 

## Step 7: Reading from the Kafka Topic

If we read from the Kafka topic that we created earlier, we should see the 3 lines in the source file that were written to Kafka:

#read all from topic
$KAFKA_HOME/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-connect-test --from-beginning
 
    this is line 1
    this is line 2
    this is line 3
    
## Congratulations! You completed this lab.